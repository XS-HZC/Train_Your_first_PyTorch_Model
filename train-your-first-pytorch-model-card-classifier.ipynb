{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# åˆ›å»ºä¸€ä¸ªå›¾åƒåˆ†ç±»å™¨æ¥è¯†åˆ«æ‰‘å…‹ç‰Œ\n",
    "\n",
    "\n",
    "å°†åˆ†ä¸‰ä¸ªéƒ¨åˆ†æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼š\n",
    "1. PyTorch æ•°æ®é›† (Dataset)\n",
    "2. PyTorch æ¨¡å‹ (Model)\n",
    "3. PyTorch è®­ç»ƒå¾ªç¯ (Training Loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¾“å‡ºå½“å‰ Python è§£é‡Šå™¨çš„ç»å¯¹è·¯å¾„ï¼Œç¡®ä¿ä½¿ç”¨çš„æ˜¯æ­£ç¡®çš„ç¯å¢ƒ\n",
    "import sys\n",
    "print('System Version:', sys.version)\n",
    "print(sys.executable)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib ï¼šå¸¸ç”¨çš„ç»˜å›¾åº“\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt # For data viz\n",
    "print(matplotlib.__version__)\n",
    "print(matplotlib.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch åŠå…¶ç›¸å…³åº“çš„ç‰ˆæœ¬ä¿¡æ¯å’Œ CUDA æ”¯æŒæƒ…å†µ\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import torchaudio\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Torchvision version:\", torchvision.__version__)\n",
    "print(\"Torchaudio version:\", torchaudio.__version__)\n",
    "\n",
    "# CUDA è¿è¡Œæ—¶ç‰ˆæœ¬ï¼ˆå¯¹åº” pytorch-cuda=12.4ï¼‰\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version used by PyTorch:\", torch.version.cuda)\n",
    "\n",
    "# å½“å‰ GPU ä¿¡æ¯\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T01:51:40.119042Z",
     "iopub.status.busy": "2025-06-01T01:51:40.118734Z",
     "iopub.status.idle": "2025-06-01T01:51:45.815226Z",
     "shell.execute_reply": "2025-06-01T01:51:45.814320Z",
     "shell.execute_reply.started": "2025-06-01T01:51:40.119009Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# timm: PyTorch å›¾åƒæ¨¡å‹åº“\n",
    "import timm\n",
    "\n",
    "# tqdm: è¿›åº¦æ¡åº“\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# numpy: æ•°å€¼è®¡ç®—åº“\n",
    "import numpy as np\n",
    "print('Numpy version', np.__version__)\n",
    "\n",
    "# pandas: æ•°æ®å¤„ç†å’Œåˆ†æåº“\n",
    "import pandas as pd\n",
    "print('Pandas version', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬ 1 æ­¥ï¼šPyTorch æ•°æ®é›†ï¼ˆä»¥åŠæ•°æ®åŠ è½½å™¨ï¼‰\n",
    "\n",
    "æŠŠæ•°æ®é›†åŒ…è£…åˆ°ä¸€ä¸ª DataLoader ä¸­ï¼ŒPyTorch ä¼šåœ¨è®­ç»ƒæ¨¡å‹æ—¶è‡ªåŠ¨å¤„ç† æ‰¹é‡åˆ’åˆ† å’Œ æ•°æ®æ‰“ä¹±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T01:58:13.768066Z",
     "iopub.status.busy": "2025-06-01T01:58:13.767391Z",
     "iopub.status.idle": "2025-06-01T01:58:13.773077Z",
     "shell.execute_reply": "2025-06-01T01:58:13.772088Z",
     "shell.execute_reply.started": "2025-06-01T01:58:13.768039Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PlayingCardDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        # ImageFolder åŠ è½½ä»¥ç‰¹å®šæ–‡ä»¶å¤¹ç»“æ„ç»„ç»‡çš„å›¾åƒæ•°æ®é›†\n",
    "        self.data = ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "    # æ•°æ®é›†ä¸­æœ‰å¤šå°‘ä¸ªç¤ºä¾‹\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    # @property æ˜¯ä¸€ä¸ªå†…ç½®çš„è£…é¥°å™¨ (decorator)ï¼Œå®ƒçš„ä¸»è¦ä½œç”¨æ˜¯å°†ä¸€ä¸ªç±»çš„æ–¹æ³•è½¬æ¢ä¸ºä¸€ä¸ªâ€œå±æ€§â€ï¼Œä½¿å¾—ç¨‹åºå‘˜å¯ä»¥åƒè®¿é—®æ™®é€šå±æ€§ä¸€æ ·è°ƒç”¨è¿™ä¸ªæ–¹æ³•ï¼Œè€Œä¸éœ€è¦ä½¿ç”¨æ‹¬å· ()\n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.data.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“‚ `torchvision.datasets.ImageFolder` ä½¿ç”¨ç¬”è®°\n",
    "\n",
    "## ğŸ—‚ï¸ æ•°æ®ç»“æ„è¦æ±‚\n",
    "<pre>my_dataset/  <-- ä¼ ç»™ ImageFolder çš„æ ¹ç›®å½•\n",
    "â”œâ”€â”€ cat/\n",
    "â”‚   â”œâ”€â”€ cat1.jpg\n",
    "â”‚   â”œâ”€â”€ cat2.jpg\n",
    "â””â”€â”€ dog/\n",
    "    â”œâ”€â”€ dog1.jpg\n",
    "    â”œâ”€â”€ dog2.jpg</pre>\n",
    "\n",
    "- **my_dataset**ï¼šæ•°æ®é›†æ ¹ç›®å½•  \n",
    "- **cat / dog**ï¼šå­æ–‡ä»¶å¤¹ï¼Œæ¯ä¸ªæ–‡ä»¶å¤¹åå³ç±»åˆ«å  \n",
    "- **é»˜è®¤å›¾åƒæ ¼å¼æ”¯æŒ**ï¼š`.jpg` `.jpeg` `.png` `.ppm` `.bmp` `.pgm` `.tif` `.tiff` `.webp`\n",
    "\n",
    "## ğŸ“¦ è¿”å›å¯¹è±¡ç±»å‹\n",
    "\n",
    "> åˆ›å»º ImageFolder ä¼šè¿”å›ï¼š  \n",
    "> **`torchvision.datasets.ImageFolder` å®ä¾‹**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“˜ torchvision.datasets.ImageFolder å®ä¾‹çš„å¸¸ç”¨æ“ä½œè¯´æ˜\n",
    "\n",
    "ä»¥ä¸‹ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å‡è®¾ä½ çš„æ•°æ®é›†å®ä¾‹ä¸ºï¼š\n",
    "\n",
    "```python\n",
    "my_dataset = ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "ç”¨æ³•: num_samples = len(my_dataset)\n",
    "\n",
    "ç”¨æ³•: my_dataset[index]ï¼Œè¿”å›: ä¸€ä¸ªå…ƒç»„ (image, label)\n",
    "    label: è¯¥å›¾åƒå¯¹åº”çš„ç±»åˆ«æ ‡ç­¾ï¼Œæ˜¯ä¸€ä¸ªæ•´æ•° (e.g., 0, 1, 2, ...)ï¼Œè¿™ä¸ªæ•´æ•°æ˜¯æ ¹æ®å­æ–‡ä»¶å¤¹åç§°ï¼ˆç±»åˆ«åç§°ï¼‰æŒ‰å­—æ¯é¡ºåºæ’åºååˆ†é…çš„ç´¢å¼•\n",
    "        ç¤ºä¾‹: sample_image, sample_label = my_dataset[0] (è·å–ç¬¬ä¸€ä¸ªæ ·æœ¬)\n",
    "\n",
    ".classes: \n",
    "    ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«äº†æ•°æ®é›†ä¸­æ‰€æœ‰ç±»åˆ«çš„åç§°ï¼ˆå³ data_dir ä¸‹å­æ–‡ä»¶å¤¹çš„åç§°ï¼‰ï¼ŒæŒ‰å­—æ¯é¡ºåºæ’åˆ—\n",
    ".class_to_idx: \n",
    "    ä¸€ä¸ªå­—å…¸ï¼Œå°†ç±»åˆ«åç§°æ˜ å°„åˆ°å®ƒä»¬å¯¹åº”çš„æ•´æ•°æ ‡ç­¾\n",
    ".imgs(æˆ–è€…åœ¨è¾ƒæ–°ç‰ˆæœ¬ä¸­æ›´é€šç”¨çš„å«æ³•æ˜¯ .samples):\n",
    "    ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªå…ƒç»„ (image_path, class_index)ï¼Œå®ƒè®°å½•äº†æ•°æ®é›†ä¸­æ¯ä¸ªè¢«æ‰¾åˆ°çš„å›¾åƒæ–‡ä»¶çš„å®Œæ•´è·¯å¾„ä»¥åŠå®ƒå¯¹åº”çš„æ•´æ•°ç±»åˆ«æ ‡ç­¾ï¼ŒæŒ‰å­—æ¯é¡ºåºæ’åˆ—\n",
    ".targets:\n",
    "    ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«äº†æ•°æ®é›†ä¸­æ¯ä¸ªæ ·æœ¬çš„æ ‡ç­¾ï¼ˆæ•´æ•°ç´¢å¼•ï¼‰ï¼Œè¿™ä¸ªåˆ—è¡¨çš„é¡ºåºä¸ .imgs (æˆ– .samples) ä¸­æ ·æœ¬çš„é¡ºåºä¸€è‡´ï¼ŒæŒ‰å­—æ¯é¡ºåºæ’åˆ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹ç±»åˆ«åç§°\n",
    "data_dir = '/home/cc/workspace/my_project/python_project/dataset/cards_dataset/train'\n",
    "target_to_class = {v: k for k, v in ImageFolder(data_dir).class_to_idx.items()}\n",
    "print(target_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T01:58:16.818189Z",
     "iopub.status.busy": "2025-06-01T01:58:16.817392Z",
     "iopub.status.idle": "2025-06-01T01:58:36.498651Z",
     "shell.execute_reply": "2025-06-01T01:58:36.498003Z",
     "shell.execute_reply.started": "2025-06-01T01:58:16.818162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = PlayingCardDataset(\n",
    "    data_dir='/home/cc/workspace/my_project/python_project/dataset/cards_dataset/train'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T01:58:54.410418Z",
     "iopub.status.busy": "2025-06-01T01:58:54.410117Z",
     "iopub.status.idle": "2025-06-01T01:58:54.416443Z",
     "shell.execute_reply": "2025-06-01T01:58:54.415607Z",
     "shell.execute_reply.started": "2025-06-01T01:58:54.410394Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T01:59:01.780423Z",
     "iopub.status.busy": "2025-06-01T01:59:01.779636Z",
     "iopub.status.idle": "2025-06-01T01:59:01.818840Z",
     "shell.execute_reply": "2025-06-01T01:59:01.817599Z",
     "shell.execute_reply.started": "2025-06-01T01:59:01.780394Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image, label = dataset[6000]\n",
    "print(label)\n",
    "image\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T02:26:28.468123Z",
     "iopub.status.busy": "2025-06-01T02:26:28.467348Z",
     "iopub.status.idle": "2025-06-01T02:26:31.743794Z",
     "shell.execute_reply": "2025-06-01T02:26:31.743073Z",
     "shell.execute_reply.started": "2025-06-01T02:26:28.468096Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    # Resize((128, 128))ï¼šæŠŠè¾“å…¥å›¾åƒç¼©æ”¾åˆ° 128 åƒç´ é«˜ã€128 åƒç´ å®½\n",
    "    transforms.Resize((128, 128)),\n",
    "    # ToTensor()ï¼šæŠŠå›¾åƒä» PIL.Image æˆ– numpy.ndarray æ ¼å¼è½¬æ¢ä¸º PyTorch å¼ é‡ï¼ˆTensorï¼‰ï¼Œå¹¶å°†å›¾åƒçš„åƒç´ å€¼ä» 0â€“255 ç¼©æ”¾åˆ° 0â€“1 èŒƒå›´\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "data_dir = '/home/cc/workspace/my_project/python_project/dataset/cards_dataset/train'\n",
    "# dataset æ˜¯ä¸€ä¸ªå¯è¿­ä»£å¯¹è±¡ï¼Œä¸æ˜¯è¿­ä»£å™¨\n",
    "dataset = PlayingCardDataset(data_dir, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T02:26:46.121068Z",
     "iopub.status.busy": "2025-06-01T02:26:46.120728Z",
     "iopub.status.idle": "2025-06-01T02:26:46.125278Z",
     "shell.execute_reply": "2025-06-01T02:26:46.124435Z",
     "shell.execute_reply.started": "2025-06-01T02:26:46.121040Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# torch.utils.data.DataLoader å¯ä»¥å¤„ç†çš„å¯¹è±¡æœ‰ä¸€ä¸ªæ˜ç¡®çš„æ ‡å‡†ï¼šå®ƒå¿…é¡»æ˜¯ä¸€ä¸ªç¬¦åˆ PyTorch Dataset æ¥å£çš„å¯¹è±¡\n",
    "# DataLoader è¿”å›ä¸€ä¸ªè¿­ä»£å¯¹è±¡ï¼Œè¿­ä»£åº¦å¯¹è±¡æ¯æ¬¡è¿”å›ä¸€ä¸ª batch çš„æ•°æ®\n",
    "# shuffle=True è¡¨ç¤ºåœ¨ä½¿ç”¨ for batch in DataLoader: å¼€å§‹è¿­ä»£ä¹‹å‰ï¼ŒDataLoader ä¼šå‡†å¤‡ä¸€ä¸ªæ–°çš„æ•°æ®é¡ºåº\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬ 2 æ­¥ï¼šPyTorch æ¨¡å‹\n",
    "\n",
    "- å¯ä»¥ä»é›¶å¼€å§‹åˆ›å»ºæ¨¡å‹ï¼Œé€å±‚å®šä¹‰æ¯ä¸ªå±‚ã€‚\n",
    "- å¯ä»¥ä»åƒ timm è¿™æ ·çš„åº“ä¸­å¯¼å…¥ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T02:26:56.917763Z",
     "iopub.status.busy": "2025-06-01T02:26:56.917019Z",
     "iopub.status.idle": "2025-06-01T02:26:56.922874Z",
     "shell.execute_reply": "2025-06-01T02:26:56.921947Z",
     "shell.execute_reply.started": "2025-06-01T02:26:56.917732Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SimpleCardClassifer(nn.Module):\n",
    "    def __init__(self, num_classes=53):\n",
    "        super(SimpleCardClassifer, self).__init__()\n",
    "        # Where we define all the parts of the model\n",
    "        # pretrained=True è¡¨ç¤ºåŠ è½½é¢„è®­ç»ƒæƒé‡ï¼Œå³ä½¿ç”¨åœ¨ ImageNet ä¸Šè®­ç»ƒå¥½çš„ EfficientNet-B0 æ¨¡å‹\n",
    "        self.base_model = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "\n",
    "        # ä½¿ç”¨ é¢„è®­ç»ƒæ¨¡å‹ï¼ˆæ¯”å¦‚ ResNetã€VGGï¼‰è¿›è¡Œè¿ç§»å­¦ä¹ æ—¶çš„æŠ€å·§ï¼š\n",
    "        # nn.Sequentialï¼šæŠŠå¤šä¸ªå±‚ï¼ˆå¦‚å·ç§¯å±‚ã€æ¿€æ´»å±‚ã€çº¿æ€§å±‚ã€æ‰¹å½’ä¸€åŒ–å±‚ç­‰ï¼‰æŒ‰é¡ºåºä¸²è”èµ·æ¥ï¼Œè°ƒç”¨å®ƒæ—¶ï¼Œä¼šæŒ‰ç…§é¡ºåº(å…ˆå°†è¾“å…¥æ•°æ®ä¼ å…¥ç¬¬ä¸€ä¸ªå‚æ•°(ç¬¬ä¸€å±‚)ï¼Œç„¶åå°†ç¬¬ä¸€å±‚è¾“å‡ºä¼ é€’ç»™ç¬¬äºŒä¸ªå‚æ•°)æŠŠè¾“å…¥æ•°æ®ä¼ é€’ç»™æ¯ä¸€å±‚ï¼Œæœ€åè¾“å‡ºæœ€åä¸€å±‚çš„ç»“æœ\n",
    "        # å½“ * ç”¨åœ¨å‡½æ•°è°ƒç”¨æ—¶ï¼Œè¡¨ç¤ºæŠŠä¸€ä¸ªåˆ—è¡¨æˆ–å…ƒç»„çš„å…ƒç´ æ‹†å¼€ï¼Œä¾æ¬¡ä½œä¸ºå‚æ•°ä¼ å…¥å‡½æ•°\n",
    "        self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n",
    "            # self.base_model.children() è¿”å›ä¸€ä¸ªè¿­ä»£å™¨ï¼ŒåŒ…å«æ¨¡å‹çš„æ‰€æœ‰å­æ¨¡å—ï¼ˆå±‚ï¼‰\n",
    "            # list(...) æŠŠè¿­ä»£å™¨è½¬æ¢ä¸ºä¸€ä¸ªåˆ—è¡¨\n",
    "            # list(self.base_model.children())[:-1] è·å–é™¤äº†æœ€åä¸€å±‚(æ­¤å¤„æœ€åä¸€å±‚æ˜¯ fc å±‚)ä¹‹å¤–çš„æ‰€æœ‰å­æ¨¡å—ï¼Œå½¢æˆä¸€ä¸ªæ–°çš„åˆ—è¡¨\n",
    "            # *list(self.base_model.children())[:-1] æŠŠè¿™ä¸ªæ–°çš„åˆ—è¡¨æ‹†å¼€ï¼Œä½œä¸ºå¤šä¸ªå‚æ•°ä¼ å…¥ nn.Sequential()ï¼Œä»è€Œåˆ›å»ºä¸€ä¸ªæ–°çš„é¡ºåºå®¹å™¨\n",
    "\n",
    "        \n",
    "        # 1280 æ˜¯ EfficientNet-B0 æ¨¡å‹åœ¨æœ€åä¸€ä¸ªå·ç§¯å±‚è¾“å‡ºçš„ç‰¹å¾å›¾é€šé“æ•°\n",
    "        enet_out_size = 1280\n",
    "        # Make a classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            # nn.Flatten() ç”¨äºå°†å¤šç»´å¼ é‡å±•å¹³æˆäºŒç»´å¼ é‡ï¼Œå½¢çŠ¶ä» [batch_size, 1280, 1, 1]ï¼ˆå‡è®¾æ˜¯å·ç§¯ç‰¹å¾å›¾ï¼‰å˜æˆ [batch_size, 1280]\n",
    "            nn.Flatten(),\n",
    "            # è¡¨ç¤ºè¾“å…¥ enet_out_size ç»´çš„ç‰¹å¾å‘é‡ï¼Œè¾“å‡º num_classes ç»´ï¼Œä»£è¡¨ num_classes ä¸ªç±»åˆ«çš„é¢„æµ‹åˆ†æ•°\n",
    "            nn.Linear(enet_out_size, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Connect these parts and return the output\n",
    "        x = self.features(x)\n",
    "        output = self.classifier(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T02:26:59.737196Z",
     "iopub.status.busy": "2025-06-01T02:26:59.736447Z",
     "iopub.status.idle": "2025-06-01T02:28:04.743984Z",
     "shell.execute_reply": "2025-06-01T02:28:04.742711Z",
     "shell.execute_reply.started": "2025-06-01T02:26:59.737157Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = SimpleCardClassifer(num_classes=53)\n",
    "print(str(model)[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:23:54.91198Z",
     "iopub.status.busy": "2023-10-05T20:23:54.911197Z",
     "iopub.status.idle": "2023-10-05T20:23:56.345511Z",
     "shell.execute_reply": "2023-10-05T20:23:56.344396Z",
     "shell.execute_reply.started": "2023-10-05T20:23:54.911948Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "example_out = model(images)\n",
    "example_out.shape # [batch_size, num_classes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬ 3 æ­¥ï¼šè®­ç»ƒå¾ªç¯ï¼ˆTraining Loopï¼‰\n",
    "\n",
    "Epochï¼šæ•´ä¸ªè®­ç»ƒæ•°æ®é›†è¢«å®Œæ•´è¿è¡Œä¸€æ¬¡\n",
    "\n",
    "Stepï¼šä¸€ä¸ª batch çš„æ•°æ®ï¼ˆç”± DataLoader å®šä¹‰ï¼‰\n",
    "\n",
    "è®­ç»ƒå¾ªç¯æµç¨‹ï¼š\n",
    "- å°†æ•°æ®ä»¥ batch çš„å½¢å¼è¾“å…¥æ¨¡å‹\n",
    "- è®¡ç®—æŸå¤±ï¼ˆlossï¼‰\n",
    "- æ‰§è¡Œåå‘ä¼ æ’­ï¼ˆbackpropagationï¼‰\n",
    "\n",
    "éœ€è¦é€‰æ‹©çš„ä¸¤æ ·ä¸œè¥¿ï¼š\n",
    "- ä¼˜åŒ–å™¨ï¼ˆoptimizerï¼‰ï¼šä¾‹å¦‚ Adam æ˜¯å¤§å¤šæ•°ä»»åŠ¡çš„è‰¯å¥½èµ·ç‚¹\n",
    "- æŸå¤±å‡½æ•°ï¼ˆloss functionï¼‰ï¼šæ¨¡å‹ä¼˜åŒ–çš„ç›®æ ‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:24:10.287635Z",
     "iopub.status.busy": "2023-10-05T20:24:10.287312Z",
     "iopub.status.idle": "2023-10-05T20:24:10.292883Z",
     "shell.execute_reply": "2023-10-05T20:24:10.29189Z",
     "shell.execute_reply.started": "2023-10-05T20:24:10.287612Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "# æŸå¤±å‡½æ•°\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer\n",
    "# ä¼˜åŒ–å™¨\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:24:10.294821Z",
     "iopub.status.busy": "2023-10-05T20:24:10.294214Z",
     "iopub.status.idle": "2023-10-05T20:24:10.30741Z",
     "shell.execute_reply": "2023-10-05T20:24:10.306497Z",
     "shell.execute_reply.started": "2023-10-05T20:24:10.294772Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(criterion(example_out, labels))\n",
    "print(example_out.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:24:10.30927Z",
     "iopub.status.busy": "2023-10-05T20:24:10.308688Z",
     "iopub.status.idle": "2023-10-05T20:24:10.431868Z",
     "shell.execute_reply": "2023-10-05T20:24:10.431054Z",
     "shell.execute_reply.started": "2023-10-05T20:24:10.30924Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_folder = '/home/cc/workspace/my_project/python_project/dataset/cards_dataset/train/'\n",
    "valid_folder = '/home/cc/workspace/my_project/python_project/dataset/cards_dataset/valid/'\n",
    "test_folder = '/home/cc/workspace/my_project/python_project/dataset/cards_dataset/test/'\n",
    "\n",
    "train_dataset = PlayingCardDataset(train_folder, transform=transform)\n",
    "val_dataset = PlayingCardDataset(valid_folder, transform=transform)\n",
    "test_dataset = PlayingCardDataset(test_folder, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T20:24:10.433488Z",
     "iopub.status.busy": "2023-10-05T20:24:10.433006Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Simple training loop\n",
    "num_epochs = 5\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# æ¨¡å‹å®ä¾‹åŒ–\n",
    "model = SimpleCardClassifer(num_classes=53)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # è®­ç»ƒé˜¶æ®µ\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc='Training loop'):\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss æ˜¯ä¸€ä¸ªæ ‡é‡å¼ é‡ï¼ˆTensor(1)ï¼‰ï¼Œè¡¨ç¤ºå½“å‰è¿™ä¸ª batch çš„å¹³å‡æŸå¤±å€¼\n",
    "        # .item() æŠŠè¿™ä¸ªå¼ é‡è½¬æ¢æˆ Python æ•°å­—ï¼ˆfloatï¼‰\n",
    "        # labels.size(0) æ˜¯å½“å‰ batch çš„å¤§å°ï¼ˆå³æœ‰å¤šå°‘ä¸ªæ ·æœ¬ï¼‰\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # è¯„ä¼°é˜¶æ®µ\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc='Validation loop'):\n",
    "            # Move inputs and labels to the device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "         \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "            \n",
    "    val_loss = running_loss / len(val_loader.dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {train_loss}, Validation loss: {val_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Losses\n",
    "\n",
    "We can plot our training and validation loss through this training, usually we do this at the end of each epoch. We see that our accuracy on the validation dataset is `x`! There are a LOT more things to learn about that can drastically improve how to train a model which I will cover in future videos, but this should give you a good start!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss over epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Bonus:** Evaluating the Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the image\n",
    "def preprocess_image(image_path, transform):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    return image, transform(image).unsqueeze(0)\n",
    "\n",
    "# Predict using the model\n",
    "def predict(model, image_tensor, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image_tensor = image_tensor.to(device)\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    return probabilities.cpu().numpy().flatten()\n",
    "\n",
    "# Visualization\n",
    "def visualize_predictions(original_image, probabilities, class_names):\n",
    "    fig, axarr = plt.subplots(1, 2, figsize=(14, 7))\n",
    "    \n",
    "    # Display image\n",
    "    axarr[0].imshow(original_image)\n",
    "    axarr[0].axis(\"off\")\n",
    "    \n",
    "    # Display predictions\n",
    "    axarr[1].barh(class_names, probabilities)\n",
    "    axarr[1].set_xlabel(\"Probability\")\n",
    "    axarr[1].set_title(\"Class Predictions\")\n",
    "    axarr[1].set_xlim(0, 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "test_image = \"/home/cc/workspace/my_project/python_project/dataset/cards_dataset/test/five of diamonds/2.jpg\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "original_image, image_tensor = preprocess_image(test_image, transform)\n",
    "probabilities = predict(model, image_tensor, device)\n",
    "\n",
    "# Assuming dataset.classes gives the class names\n",
    "class_names = train_dataset.classes\n",
    "visualize_predictions(original_image, probabilities, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "# glob ç”¨äº æŸ¥æ‰¾ç¬¦åˆç‰¹å®šè·¯å¾„æ¨¡å¼çš„æ–‡ä»¶\n",
    "# glob å‡½æ•°åŒ¹é…è·¯å¾„ /home/cc/.cache/kagglehub/.../test/*/* ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ï¼š\n",
    "    # ç¬¬ä¸€ä¸ª * å¯¹åº” ç±»åˆ«æ–‡ä»¶å¤¹ï¼ˆå¦‚ cat/ã€dog/ï¼‰\n",
    "    # ç¬¬äºŒä¸ª * å¯¹åº” å›¾ç‰‡æ–‡ä»¶åï¼ˆå¦‚ cat1.jpgã€dog2.jpgï¼‰\n",
    "# è¿”å›å€¼ test_images æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ éƒ½æ˜¯å›¾ç‰‡çš„å®Œæ•´è·¯å¾„å­—ç¬¦ä¸²\n",
    "test_images = glob('/home/cc/workspace/my_project/python_project/dataset/cards_dataset/test/*/*')\n",
    "\n",
    "# è¿”å›å€¼ test_examples æ˜¯ä¸€ä¸ªé•¿åº¦ä¸º 10 çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå›¾ç‰‡è·¯å¾„å­—ç¬¦ä¸²\n",
    "test_examples = np.random.choice(test_images, 10)\n",
    "\n",
    "for example in test_examples:\n",
    "    original_image, image_tensor = preprocess_image(example, transform)\n",
    "    probabilities = predict(model, image_tensor, device)\n",
    "\n",
    "    # Assuming dataset.classes gives the class names\n",
    "    class_names = train_dataset.classes \n",
    "    visualize_predictions(original_image, probabilities, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "\n",
    "- Calculate the accuracy of our model on the validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing phase\n",
    "model.eval()\n",
    "running_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc='Testing loop'):\n",
    "        # Move inputs and labels to the device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "     \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "test_loss = running_loss / len(test_loader.dataset)\n",
    "print(f\"Test loss: {test_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2579480,
     "sourceId": 4532039,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
